{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9825798,
          "sourceType": "datasetVersion",
          "datasetId": 6025550
        },
        {
          "sourceId": 165411,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 140744,
          "modelId": 163349
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "MinimalDiffusion",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spran180/SAR-Image-Colorization/blob/main/MinimalDiffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "qPXa_b56dT2Q"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "pranavsharma1808_sar_dataset_path = kagglehub.dataset_download('pranavsharma1808/sar-dataset')\n",
        "pranavsharma1808_diffusionmodel_pytorch_default_1_path = kagglehub.model_download('pranavsharma1808/diffusionmodel/PyTorch/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "FRBYJJGwdT2R"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "of1-c2V6dT2S"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Diffusers\n",
        "!pip install pillow"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T14:11:49.866007Z",
          "iopub.execute_input": "2024-11-13T14:11:49.867274Z",
          "iopub.status.idle": "2024-11-13T14:12:16.506973Z",
          "shell.execute_reply.started": "2024-11-13T14:11:49.867232Z",
          "shell.execute_reply": "2024-11-13T14:12:16.505967Z"
        },
        "id": "K_SsQCbbdT2T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from diffusers import DDPMScheduler, UNet2DModel\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device = {device}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T15:03:09.747371Z",
          "iopub.execute_input": "2024-11-13T15:03:09.748098Z",
          "iopub.status.idle": "2024-11-13T15:03:17.126112Z",
          "shell.execute_reply.started": "2024-11-13T15:03:09.748046Z",
          "shell.execute_reply": "2024-11-13T15:03:17.125095Z"
        },
        "id": "MPJkYVCpdT2T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class SarOpticalDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, sar_path, opt_path, transform=None):\n",
        "        self.sar_dirs = sar_path\n",
        "        self.opt_dirs = opt_path\n",
        "        self.transform = transform\n",
        "        self.image_filenames = [f for f in os.listdir(sar_path) if os.path.isfile(os.path.join(sar_path, f))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sar_image_path = os.path.join(self.sar_dirs, self.image_filenames[idx])\n",
        "        sar_image = Image.open(sar_image_path)\n",
        "\n",
        "        optical_image_path = os.path.join(self.opt_dirs, self.image_filenames[idx])\n",
        "        optical_image = Image.open(optical_image_path)\n",
        "\n",
        "        if(self.transform):\n",
        "            sar_image = self.transform(sar_image)\n",
        "            optical_image = self.transform(optical_image)\n",
        "\n",
        "        return sar_image, optical_image"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T15:06:00.043256Z",
          "iopub.execute_input": "2024-11-13T15:06:00.043697Z",
          "iopub.status.idle": "2024-11-13T15:06:00.052314Z",
          "shell.execute_reply.started": "2024-11-13T15:06:00.043657Z",
          "shell.execute_reply": "2024-11-13T15:06:00.051304Z"
        },
        "id": "GG9knM9bdT2T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Reduce image size\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "sar_path = '/kaggle/input/sar-dataset/QXSLAB_SAROPT/sar_256_oc_0.2'\n",
        "opt_path = '/kaggle/input/sar-dataset/QXSLAB_SAROPT/opt_256_oc_0.2'\n",
        "\n",
        "dataset = SarOpticalDataset(sar_path=sar_path, opt_path=opt_path, transform=transform)\n",
        "train_dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T15:06:00.714032Z",
          "iopub.execute_input": "2024-11-13T15:06:00.714743Z",
          "iopub.status.idle": "2024-11-13T15:06:13.863782Z",
          "shell.execute_reply.started": "2024-11-13T15:06:00.714702Z",
          "shell.execute_reply": "2024-11-13T15:06:13.862656Z"
        },
        "id": "TjmPa66QdT2U"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicUNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channel=1, out_channel=3):\n",
        "        super().__init__()\n",
        "        self.down_layers = torch.nn.ModuleList([\n",
        "            nn.Conv2d(in_channel, 32, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
        "        ])\n",
        "        self.up_layers = torch.nn.ModuleList([\n",
        "            nn.Conv2d(64, 64, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(64, 32, kernel_size=5, padding=2),\n",
        "            nn.Conv2d(32, out_channel, kernel_size=5, padding=2)\n",
        "        ])\n",
        "\n",
        "        self.act = nn.SiLU()\n",
        "        self.downscale = nn.MaxPool2d(2)\n",
        "        self.upscale = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = []\n",
        "        for i, l in enumerate(self.down_layers):\n",
        "            x = self.act(l(x))\n",
        "            if i < 2:\n",
        "                h.append(x)\n",
        "                x = self.downscale(x)\n",
        "\n",
        "        for i, l in enumerate(self.up_layers):\n",
        "            if i > 0:\n",
        "                x = self.upscale(x)\n",
        "                x += h.pop()\n",
        "            x = self.act(l(x))\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T15:06:20.78088Z",
          "iopub.execute_input": "2024-11-13T15:06:20.781522Z",
          "iopub.status.idle": "2024-11-13T15:06:20.79143Z",
          "shell.execute_reply.started": "2024-11-13T15:06:20.781483Z",
          "shell.execute_reply": "2024-11-13T15:06:20.790431Z"
        },
        "id": "oIqdsJzrdT2W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def print_image(x, y):\n",
        "    grid_img = torchvision.utils.make_grid(x)\n",
        "\n",
        "    # Convert tensor to a NumPy array and adjust the range if necessary\n",
        "    np_img = grid_img.numpy().transpose((1, 2, 0)).clip(0, 1)\n",
        "\n",
        "    # Display the image with Matplotlib\n",
        "    plt.imshow(np_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    grid_img = torchvision.utils.make_grid(y)\n",
        "\n",
        "    # Convert tensor to NumPy array and clip values\n",
        "    np_img = grid_img.numpy().transpose((1, 2, 0)).clip(0, 1)\n",
        "\n",
        "    # Display predictions with Matplotlib\n",
        "    plt.imshow(np_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # Model predictions\n",
        "    with torch.no_grad():\n",
        "        preds = net(x.to(device), 0).sample.detach().cpu()\n",
        "\n",
        "    # Create a grid from predictions\n",
        "    grid_img = torchvision.utils.make_grid(preds)\n",
        "\n",
        "    # Convert tensor to NumPy array and clip values\n",
        "    np_img = grid_img.numpy().transpose((1, 2, 0)).clip(0, 1)\n",
        "\n",
        "    # Display predictions with Matplotlib\n",
        "    plt.imshow(np_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T17:29:04.14727Z",
          "iopub.execute_input": "2024-11-13T17:29:04.147669Z",
          "iopub.status.idle": "2024-11-13T17:29:04.157548Z",
          "shell.execute_reply.started": "2024-11-13T17:29:04.147632Z",
          "shell.execute_reply": "2024-11-13T17:29:04.156314Z"
        },
        "id": "8l8bbHiEdT2W"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataLoader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "n_epoch = 3\n",
        "\n",
        "net = model = UNet2DModel(\n",
        "    sample_size=28,  # the target image resolution\n",
        "    in_channels=1,  # the number of input channels, 3 for RGB images\n",
        "    out_channels=3,  # the number of output channels\n",
        "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
        "    block_out_channels=(32, 64, 64),  # Roughly matching our basic unet example\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
        "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
        "        \"AttnDownBlock2D\",\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
        "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
        "    ),\n",
        ").to(device)\n",
        "\n",
        "loss_fun = nn.MSELoss()\n",
        "\n",
        "opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    for x, y in train_dataLoader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        pred = net(x, 0).sample\n",
        "        loss = loss_fun(pred, y)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "    avg_loss = sum(losses[-len(train_dataloader) :]) / len(train_dataloader)\n",
        "    print(f\"Finished epoch {epoch}. Average loss for this epoch: {avg_loss:05f}\")\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.ylim(0, 0.1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "QmzjuIZmdT2X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T12:53:55.927255Z",
          "iopub.execute_input": "2024-11-13T12:53:55.928281Z",
          "iopub.status.idle": "2024-11-13T13:02:46.802933Z",
          "shell.execute_reply.started": "2024-11-13T12:53:55.928233Z",
          "shell.execute_reply": "2024-11-13T13:02:46.801957Z"
        },
        "id": "pLumx7PEdT2X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(net.state_dict(), 'model_parameters_3.pth')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T17:27:20.054873Z",
          "iopub.execute_input": "2024-11-13T17:27:20.055328Z",
          "iopub.status.idle": "2024-11-13T17:27:20.112545Z",
          "shell.execute_reply.started": "2024-11-13T17:27:20.055278Z",
          "shell.execute_reply": "2024-11-13T17:27:20.111435Z"
        },
        "id": "WryhFQwldT2X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "net.load_state_dict(torch.load('/kaggle/input/diffusionmodel/pytorch/default/1/model_parameters_2.pth'))\n",
        "net.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T14:16:10.390484Z",
          "iopub.execute_input": "2024-11-13T14:16:10.390844Z",
          "iopub.status.idle": "2024-11-13T14:16:10.418475Z",
          "shell.execute_reply.started": "2024-11-13T14:16:10.390812Z",
          "shell.execute_reply": "2024-11-13T14:16:10.417619Z"
        },
        "id": "2BEa5uTzdT2X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Images are not very good"
      ],
      "metadata": {
        "id": "Qtmua8Z4dT2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x, y = next(iter(train_dataLoader))\n",
        "x = x[:8]  # Select the first 8 images\n",
        "\n",
        "# Create a grid from the batch of images\n",
        "print_image(x[:8], y[:8])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T17:33:35.807862Z",
          "iopub.execute_input": "2024-11-13T17:33:35.80853Z",
          "iopub.status.idle": "2024-11-13T17:33:36.964504Z",
          "shell.execute_reply.started": "2024-11-13T17:33:35.808489Z",
          "shell.execute_reply": "2024-11-13T17:33:36.963194Z"
        },
        "id": "7ybuIHj8dT2a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'entire_model.pth')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-11-13T17:33:06.071613Z",
          "iopub.execute_input": "2024-11-13T17:33:06.072507Z",
          "iopub.status.idle": "2024-11-13T17:33:06.143304Z",
          "shell.execute_reply.started": "2024-11-13T17:33:06.072463Z",
          "shell.execute_reply": "2024-11-13T17:33:06.142497Z"
        },
        "id": "cw1VnZfLdT2b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "slK3QyLOdT2c"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}